---
layout: wiki  # 使用wiki布局模板
wiki: Operating system # 这是项目名
title: CPU Cache
order: 52
---

**CPU Cache 的数据结构和读取过程**

1. L1 Cache 和 L2 Cache 都是每个 CPU 核心独有的，而 L3 Cache 是多个 CPU 核心共享的。

2. 层次关系图：<img src="http://pic.shixiaocaia.fun/202208161809033.png" alt="img" style="zoom:50%;" />
     程序执行时，会先将内存中的数据加载到共享的 L3 Cache 中，再加载到每个核心独有的 L2 Cache，最后进入到最快的 L1 Cache，之后才会被 CPU 读取。

3. CPU Cache中各项定义

     > - **Cache Line（缓存块）:**是 CPU 从内存读取数据的基本单位，计算机是一块一块读取数据。Cache Line 是由各种标志（Tag）+ 数据块（Data Block）组成。
     > - **内存块（**Block**）：**CPU读取内存数据时，一小块数据的大小是取决于 `coherency_line_size` 的值，一般 64 字节。
     > - **字（**Word**）:**CPU Cache Line中一块数据片段。

4. 那 CPU 怎么知道要访问的内存数据，是否在 Cache 里？如果在的话，如何找到 Cache 对应的数据呢？

     > - 对于直接映射 Cache 采用的策略，就是把内存块的地址始终「映射」在一个 CPU Cache Line（缓存块） 的地址，映射关系是使用「取模运算」，取模运算的结果就是内存块地址对应的 CPU Cache Line（缓存块） 的地址。
     > - 为了应对不同映射到同一个CPU CAche，缓存块中还包含了组标记Tag、数据Data、有效位Valid bit。

5. 如果内存中的数据已经在 CPU Cahe 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：<img src="http://pic.shixiaocaia.fun/202208161821437.png" alt="img" style="zoom:50%;" />
   1. 根据内存地址中索引信息，计算在 CPU Cahe 中的索引，也就是找出对应的 CPU Cache Line 的地址；
   2. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；
   3. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；
   4. 根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。

**如何写出让 CPU 跑得更快的代码？**

如果 CPU 所要操作的数据在 CPU Cache 中的话，这样将会带来很大的性能提升。访问的数据在 CPU Cache 中的话，意味着**缓存命中**，缓存命中率越高的话，代码的性能就会越好，CPU 也就跑的越快。

分开来看「数据缓存」和「指令缓存」的缓存命中率

栗子：

- 对于数据缓存，我们在遍历数据的时候，应该按照内存布局的顺序操作，这是因为 CPU Cache 是根据 CPU Cache Line 批量操作数据的，所以顺序地操作连续内存数据时，性能能得到有效的提升；
- 对于指令缓存，有规律的条件分支语句能够让 CPU 的分支预测器发挥作用，进一步提高执行的效率；