## 概念

**写回和写通**

> 1. Write-through: When data is updated, it is written to both the cache and the back-end storage. 
>
>   This mode is easy for operation but is slow in data writing because data has to be written to both the cache and the storage.
>
> 2. Write-back: When data is updated, it is written only to the cache. The modified data is written to the back-end storage only when data is removed from the cache. 
>
>   This mode has fast data write speed but data will be lost if a power failure occurs before the updated data is written to the storage.
>

## 无存储现象

最简单的存储器抽象是根本没有抽象的。

在没有存储器抽象的系统中实现并行的一种方法是使用多线程编程。也可以通过将内存中的内容暂时存到磁盘中，读入下一个程序到内存当中。保证一个时间内内存中只有一个程序，就不会产生冲突。

## 地址空间

### 概念

地址空间是一个进程可以用于寻址内存的一套地址集合。

每一个程序都有一个自己独有的地址空间，使得一个程序对应的地址28所对应的物理地址与另一个程序中的地址28所对应的物理地址不同。

> 主存中每个字节都有一个选自虚拟地址空间的虚拟地址和一个选自物理地址空间的物理地址。
>
> 现代操作系统32，64位，是指虚拟地址空间的位数。

**基址寄存器与界限寄存器**

使用动态定位，将每个进程的地址空间映射到物理内存的不同部分。

经典办法通过两个特殊寄存器实现。基址寄存器用于存放程序物理地址，界限寄存器存放了程序的长度。

在每个地址送到内存之前，会自动加上基址寄存器的内容，同时也要判断地址越界问题。

> 实际中使用这个方法较慢，因为加法运算进位传递问题，在没有使用特殊电路时很慢。

### 交换技术

一个进程完整调入内存当中，但是往往一个系统需要同时运行大量的进程，如果把所有进程加载到内存当中，内存不够的情况下是做不到。

实现内存超载的技术，交换技术，虚拟内存。

**交换技术**将空闲的进程主要存储在磁盘上，当它们不运行时就不会加载到内存中。

在内存空间没有用完时，可以加载多个进程，当内存空间不够用时，将暂时不适用的进程交换到磁盘当中，腾出空间可以加载其他进程。

这样就会带来一个问题，**内存紧缩**问题

> 在我们使用上一个进程交换腾出的空间时，可能会造成多个空闲区。
>
> 可以通过将进程向下移动，有可能将这些空闲区合并，称为内存紧缩。
>
> 但是实际中我们并不这样使用，会耗费大量的CPU时间。

另一个问题是，考虑进程的数据段增长问题：

> 如果与空闲区相邻，可以直接分配。如果是和进程相邻，要交换到更大空闲区当中。否则的话只能挂载到磁盘当中，知道有足够的空闲空间使用。
>
> 考虑大多数进程在运行时数据段都会增长，在进程换入或者移动进程时分配一些**额外的内存**。
>
> 为了节省空闲区，避免交换时浪费，可以考虑两个相邻的进程，共用一段空闲区，从不同的方向进行增长。

### 空闲内存管理

针对动态分配内存，操作系统必须对其进行管理：

**位图**

将内存划分成多个分配单元，每个分配单元对应位图中一位，0表示空闲，1表示占用。

分配单元的大小是一个重要的设计问题，过小位图过大，过大会造成一定数量的内存大小浪费。

**链表**

维护一个记录已分配内存段和空闲内存端的链表。

一个链表结点或者包含一个进程，或者是两个进程间的一块空闲区。

当按照地址顺序在链表中存放进程和空闲区时，有以下的几种算法为创建的进程分配空间。

**首次适配（first fit）**

沿着段链表进行搜索，知道找到一个足够大的空闲区。一般情况下将空闲区分为供进程使用和为下一次划分的空闲区使用。

**下次适配（next fit）**

在首次适配的基础上，使用上一次划分后的空闲区，而不是重头开始找合适的空闲区。

**最佳匹配（best fit）**

搜索整个链表，从开始到结束，找出能够容纳进程的最小空间，而不是通过拆分的方法。

可以通过设置两个链表分别存放空闲区信息和进程实际存放，对空闲区进行排序，找到的第一个就是最佳适配这个进程的最小空间。

**快速适配（quick fit）**

为那些常用的空闲区维护单独的链表。

但是当一个进程使用空闲区，剩下的空闲区需要进行合并，否则无法利用小空闲区。

### 虚拟内存

> 使用虚拟内存主要是基于下面三个考虑：
>
> 1. 可以更有效率的使用内存：使用 DRAM 当做部分的虚拟地址空间的缓存
> 2. 简化内存管理：每个进程都有统一的线性地址空间
> 3. 隔离地址控件：进程之间不会相互影响；用户程序不能访问内核信息和代码

交换技术带来一个问题就是，磁盘的交换速度有限，但是进程的大小在不断的增加。

虚拟内存的思路是每个程序都有自己的地址空间，每个空间被分配成多个块，每一个块被称为一页或者**页面**，每一页都有连续的地址范围，这些页又映射到内存当中。

**分页**

> 我们程序所使用的内存地址叫做**虚拟内存地址**（*Virtual Memory Address*）
>
> 实际存在硬件里面的空间地址叫**物理内存地址**（*Physical Memory Address*）
>
> 用SRAM缓存表示位于CPU和贮存之间的L1、L2、L3高速缓存，用DRAM缓存表示虚拟内存系统的缓存，她在主存中缓存虚拟页。

在使用虚拟内存的情况下，虚拟地址不是直接送到内存总线上，而是被送到内存管理单元（MMU），MMU把虚拟地址映射为物理内存地址。

> 虚拟地址空间按照固定大小划分成的单元称为**页面**，通常分为未分配的页、缓存的、未缓存的三类页面。
>
> 在物理内存中对应的单元称为**页框**。

当程序访问一个未被映射的**页面**时，MMU发现后，使得CPU陷入到操作系统中，这个陷阱称为**缺页中断**或者**缺页错误**。（也就是DRAM缓存**未命中**）

> 这时候OS会去找一个很少使用的页框将之存放到磁盘当中，然后将需要访问的页面放到该页框中，修改映射关系，然后重启刚才引发陷阱的命令。

> **页面大小**
>
> 对应一个虚拟地址4096，将输入16位地址分为4位的页号和12位的偏移量。
>
> 4位页号可以表示2<sup>4</sup> = 16个页面，和12位偏移量可以作为一页内的全部4096个字节编址。

对于虚拟内存的每个页面，可以用页号作为页表的索引，从而得出对应于该虚拟页面的页框号。如果存在的话，页框号位物理地址的高三位，再加上虚拟地址的低12位偏移量，构成了实际的15位物理地址。

**页表**

在上面也提到了，页表的目的是将虚拟页面映射成存放物理地址的页框。

> 从数学角度来看，页表是一个函数，参数是虚拟页号，结果是物理页框号。
>
> 通过这个函数可以把虚拟地址中的虚拟页面域替换为页框域。
>
> 包含了有效位判断虚拟页是否缓存在DRAM中，如果是后面的地址为表示其在DRAM中相应的物理页的起始位置。否则就是虚拟也在磁盘上的起始位置。
>
> 注意**多个虚拟页面可以映射到同一个共享物理页面上**。

虚拟内存的本质上是用来创造一个新的抽象概念——地址空间，是对物理内存的抽象。将虚拟内存分成多页，每一页映射到物理内存中的某个页框或者暂时解除映射。

> 页表项
>
> 常见的是SUP位是否需要内核模式才能访问，以及READ、WRITE位来控制读写。
>
> 1. 保护位：为了控制什么类型的访问，比如读，写，运行，如果超出权限，即非法访问。
> 2. 修改位：如果产生写操作，就会自动设置修改位。对于操作系统可以通过这位来判断加载在内存当中和磁盘中的文件的区别。
> 3. 访问位：来帮助操作系统在缺页中断时选择要进行淘汰的位。
> 4. 高速缓存位：禁止某一个页面被高速缓存。可以用来硬件不断地从设备中读入实时数据，而不是从高速缓存副本中读取。

**加速分页过程**

分页系统中需要考虑两个问题：

> 1. 虚拟地址到物理地址的映射必须非常快。
>
> 因为每次访问内存都需要进行虚拟地址到物理地址的映射，所有指令都必须来自内存，并且很多指令也会访问内存中的指令。
>
> 2. 如果虚拟地址空间过大，页表也会非常大。
>
> 系统的位数从32提升到64位，并且每个进程都有自己的页表，造成了页表变大。

**转换检测缓冲区**

> 利用计算机的局部性原理，整个程序的执行仅限于程序中的某一部分。相应地，执行所访问的存储空间也局限于某个内存区域。

在我阅读看来这是一个存放**常用的页面**信息的地方，快速查找到相应的页框号，而不用再去一页页查询。

TLB是通过计算机一个小型的硬件设备，将虚拟地址直接映射成物理地址，而不必再访问页表。这种设备称为转换检测缓冲区（Translation Lookaside Buffer， TLB）。有时也称为快表或者相联存储器。

![img](http://pic.shixiaocaia.fun/202211291855596.png)

在 CPU 芯片里面，封装了内存管理单元（*Memory Management Unit*）芯片，它用来完成地址转换和 TLB 的访问与交互。

有了 TLB 后，那么 CPU 在寻址时，会先查 TLB，如果没找到，才会继续查常规的页表。

TLB 的命中率其实是很高的，因为程序最常访问的页就那么几个。

**软件TLB管理**

区分两种TLB失效

> 当一个页面访问在内存中而不在TLB中时，产生软失效。
>
> 页面不在内存中，产生硬失效。

**多级页表**

在前面我们知道了，对于单页表的实现方式，在 32 位和页大小 `4KB` 的环境下，一个进程的页表需要装下 100 多万个「页表项」，并且每个页表项是占用 4 字节大小的，于是相当于每个页表需占用 4MB 大小的空间。

我们把这个 100 多万个「页表项」的单级页表再分页，将页表（一级页表）分为 `1024` 个页表（二级页表），每个表（二级页表）中包含 `1024` 个「页表项」，形成**二级分页**。如下图所示：

![img](http://pic.shixiaocaia.fun/202211291844000.png)

实际上所占用的是使用到的某个一级页表的页表项，这要未被使用的一级页表项，就不需要创建这个页表项对应的二级项表，即可以在需要时才创建二级页表。这样就会节省大量的内存空间。

> 我们从页表的性质来看，保存在内存中的页表承担的职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以**页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项**（此时一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建）。

如果把二级分页再推广到多级页表，就会发现页表占用的内存空间更少。在64位的系统，两级分页肯定不够，就变成了四级目录

- 全局页目录项 PGD（*Page Global Directory*）；
- 上层页目录项 PUD（*Page Upper Directory*）；
- 中间页目录项 PMD（*Page Middle Directory*）；
- 页表项 PTE（*Page Table Entry*）；

![img](http://pic.shixiaocaia.fun/202211291853510.png)

**段页式内存管理**

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：

![img](http://pic.shixiaocaia.fun/202211291857684.png)

段页式地址变换中要得到物理地址须经过三次内存访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。
