## 感知机

**感知机是什么**

![image-20220926191325814](http://pic.shixiaocaia.fun/202209261913508.png)

> 这是一个已接受两个输入信号的感知机。
>
> 神经元、节点：图中的圈
>
> 感知机的信号，0 对应不传递的信号， 1 对应传递信号。
>
> 界限值/阈值：用$\theta$表示。
>
> 偏置b：$-\theta$。控制神经元单元被激活的难易程度。
>
> 用公式表示感知机：
>
> ![image-20220927192052756](C:\Users\17599\AppData\Roaming\Typora\typora-user-images\image-20220927192052756.png)
>
> 重定义为，也称h(x)为激活函数：
>
> ![image-20220927192410664](http://pic.shixiaocaia.fun/202209271924901.png)

- 输入信号 x 被送往神经元，再乘以固定的权重 w, 神经元会计算传送过来的信号综合 y ， y 大于特定值时才会输出 1 ，此时称为神经元**被**激活。

> 每个输入信号的权重w类似电路中电阻，控制着信号流动程度。权重越大，该信号的重要性就越强。

**感知机实现逻辑电路**

通过改变权值和阈值，实现与门、与非门、或门。

> 但是无法用一条直线实现异或门。由此推出了**单层**感知机的局限性：只能通过一条曲线分割空间，曲线无法用感知机表示。单层感知机只能表示线性空间。
>
> 但不要灰心，我们可以通过叠加实现。

**多层感知机**

由叠加层实现异或门，引出了什么是多层感知机。

多层感知机可以实现非线性空间。

多层感知机牛逼到可以实现计算机。

## 神经网络

在上面谈到通过调正感知机的权重，实现了逻辑电路，但这都是通过人工决定。

神经网络的出现就是为了解决上述问题。神经网络的一个重要性质是它可以自动地从数据中学习到合适的权重参数。

**神经网络的例子**

![image-20220927191553905](http://pic.shixiaocaia.fun/202209271915695.png)

> 第0层：输入层。
>
> 第1层：中间层也称为隐藏层，隐藏是指隐藏的神经元。
>
> 第2层：输出层。
>
> 由于实际只有两层神经网络有权重，因此称为2层网络。也有书根据三层网络，称之为3层网络。

### 激活函数

在上方我们已经见识到了激活函数，他是将输入信号的总和转换为输出信号的函数。

激活函数分为很多种，对于这里的感知机使用了阶跃函数，即一旦输入超过阈值，就切换输出。

**sigmoid函数**

![image-20220927193009185](http://pic.shixiaocaia.fun/202209271930468.png)

```python
>>> x = np.array([-1.0, 1.0, 2.0])
>>> sigmoid(x)
```

**ReLU函数**

![image-20220927194327948](http://pic.shixiaocaia.fun/202209271943976.png)

```python
def relu(x): 
    return np.maximum(0, x)
```

> 神经网络的激活函数必须使用非线性函数。
>
> 换句话说，激活函数不能使用线性函数。因为使用线性函数的话，加深神经网络的层数就没有意义了,多次的线性激活函数，可能等价于一次的效果。

**认识权重的符号**

![image-20220927195530798](http://pic.shixiaocaia.fun/202209271955095.png)

![image-20220927200058980](http://pic.shixiaocaia.fun/202209272001702.png)

> 隐藏层的加权和（加权信号和偏置的总和）用a表示。
>
> 被激活函数转换后的信号用z表示。
>
> 图中h()表示激活函数

### 输出层的设计

神经网络可以用在分类问题和回归问题上，不过需要根据情况改变输出 层的激活函数。一般而言，回归问题用恒等函数，分类问题用softmax函数。

> 机器学习的问题大致可以分为分类问题和回归问题。分类问题是数 据属于哪一个类别的问题。比如，区分图像中的人是男性还是女性 的问题就是分类问题。而回归问题是根据某个输入预测一个（连续的） 数值的问题。比如，根据一个人的图像预测这个人的体重的问题就
> 是回归问题。

**恒等函数**

输入是什么，输出就是什么，不多说。

**softmax函数**

![image-20220927201127472](http://pic.shixiaocaia.fun/202209272011428.png)

分子是输入信号a<sub>k的</sub>指数函数，分母是所有输入信号的指数函数的和。
